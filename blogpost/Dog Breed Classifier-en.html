<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Mehmet Emre Toktay</title>
    <meta name="description" content="Mehmet Emre Toktay is a writer and computer scientist. She works to bring the best engineering practices to machine learning production.">
    <link rel="stylesheet" href="../main.css">
    <link rel="canonical" href="https://memretoktay.net">
    <link rel="alternate" type="application/rss+xml" title="Mehmet Emre Toktay" href="/feed.xml">
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5SMHCSCCLY"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-5SMHCSCCLY');
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script type="text/javascript" src="https://pixel-v0.wl.r.appspot.com/static/pixel.js"></script>
    <script type="text/javascript">
      let ccid = "memretoktay.net";
      cc(ccid);
    </script>
    <style>
        .language-selector {
            display: inline-block;
            margin-right: 0px;  /* margin miktarını azalttık */
        }
        .language-selector a {
            margin-left: 0px;
            margin-right: 0px;
            text-decoration: underline;  /* altı çizili yapmak için */
            color: black;  /* siyah renk */
        }
    </style>

  </head>

  <body>
    <body>
        <header class="site-header" role="banner">
          <div class="wrapper">
            <a class="site-title" href="/">Mehmet Emre Toktay</a>
            <nav class="site-nav">
              <input type="checkbox" id="nav-trigger" class="nav-trigger" />
              <label for="nav-trigger">
                <span class="menu-icon">
                  <svg viewBox="0 0 18 15" width="18px" height="15px">
                    <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" />
                    <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" />
                    <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" />
                  </svg>
                </span>
              </label>
              <div class="trigger">
                <a class="page-link" href="../cv/Resume & CV-en.html">Resume & CV</a>
                <a class="page-link" href="../pardus/Pardus-en.html">Pardus</a>
                <a class="page-link" href="../blog/blog-en.html">Blog</a>
                <div class="language-selector">
                <a href="Dog Breed Classifier.html">TR</a> | <a href="Dog Breed Classifier-en.html">EN</a>

              </div>
            </nav>
          </div>
          <main class="page-content" aria-label="Content">
            <div class="wrapper">
              <article class="post">
                <header class="post-header">
                    <h1 class="post-title" itemprop="name headline"></h1>
                    <p class="post-meta">
                        <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">18/07/2023 • Mehmet Emre Toktay</span></span>
                    </p>
                </header>
                <h1><b>Dog Breed Classification Using Convolutional Neural Networks</b></h1>
              	<p>Dogs have been our loyal companions for thousands of years, providing love, companionship, and protection. They come in various shapes, sizes, and temperaments, each breed with its own unique characteristics. There always been growing interest in understanding the various dog breeds, as this knowledge helps in identifying breed-specific health issues and guides us in building strong connections with these lovable creatures.</p>
                <head>
                	<title>Displaying Images Side by Side</title>
                	<style>
                		.column {
                			float: left;
                			width: 50%;
                		}
                	</style>
                </head>
                <body>
                	<div class="row">
                		<div class="column">
                			<img src="lili1.jpg" alt="Image 1">
                		</div>
                		<div class="column">
                			<img src="lili2.jpg" alt="Image 2">
                		</div>
                	</div>
                </body>
                <p>In this project, we have developed a dog breed classifier using Convolutional Neural Networks (CNN) that can accurately identify a dog's breed from its image. This classifier can be useful for potential pet owners looking to learn more about the breed of a dog they wish to adopt or for those who simply want to understand the breed-specific characteristics of their furry friends.
              </p>
              <h1><b>Overview</b></h1>
          <p>The dog breed classifier project aims to accurately identify dog breeds from images using Convolutional Neural Networks (CNNs). The classifier is capable of predicting the breed of a dog with high accuracy and can also differentiate between human and dog images. If a human image is provided, the model suggests the most resembling dog breed.Also show three possibles. Some examples:</p>
            <head>
              <title>Displaying Images Side by Side</title>
              <style>
                .column {
                  float: left;
                  width: 50%;
                }
              </style>
            </head>
              <body>
                <div class="row">
                  <div class="column">
                    <img src="resultdog.png" alt="Image 1">
                  </div>
                  <div class="column">
                    <img src="resulthuman.png" alt="Image 2">
                  </div>
                </div>
              </body>
          <p>The project involves several steps, including: </p>
          <p> <b>1.  Data loading and preprocessing </b>: The code first loads the dog dataset and splits it into training, validation, and test sets using the load_dataset function. It also loads and shuffles human images for use in the human face detection task. </p>

          <p> <b>2. Human face detection</b>: The code uses OpenCV's Haar cascade classifier for frontal face detection. The face_detector function takes an image path as input and returns True if it detects a face in the image, and False otherwise. It then calculates the percentage of human faces detected in human and dog images.</p>

          <p> <b>3. Dog detection using ResNet50</b>: The code uses the pre-trained ResNet50 model to detect dogs in the images. The dog_detector function takes an image path as input and returns True if the model predicts the image to be a dog, and False otherwise. It then calculates the percentage of dogs detected in human and dog images.</p>

          <p> <b>4. Convolutional Neural Networks model </b>:The code defines a CNN model , compiles it, and trains it using the training set. The model is then evaluated on the test set to obtain the test accuracy.</p>

          <p> <b>5. Transfer learning with VGG16</b>: The code loads the bottleneck features obtained from the VGG16 model and creates a new model by adding a global average pooling layer followed by a dense layer with 133 output nodes (corresponding to the dog breeds). The model is compiled, trained, and evaluated on the test set to obtain the test accuracy.</p>

          <p> <b> 6. Transfer learning with ResNet50 </b>: The code loads the bottleneck features obtained from the ResNet50 model and creates a new model by adding a global average pooling layer followed by a dense layer with 133 output nodes (corresponding to the dog breeds). The model is compiled, trained, and evaluated on the test set to obtain the test accuracy.</p>

          <p> <b> 7. Dog breed prediction </b>: The code defines a dog_breed function that takes an image path as input and returns the top three predicted dog breeds along with their probabilities. The dog_breed_detector function displays the input image and provides dog breed predictions for both human and dog images.</p>

          <p>The code demonstrates the process of building a dog breed classifier using deep learning techniques, including face detection, transfer learning with pre-trained models (ResNet50 and VGG16), and creating a CNN. The final part of the code predicts the dog breed for a given image, whether it contains a dog or a human face.</p>

          <h1><b>Strategy for solving the problem</b>
          </h1>
          <p>In this project, our goal is to build a model that can accurately classify dog breeds based on images. To tackle this problem, we employ three different strategies: creating a CNN, using transfer learning with VGG16, and using transfer learning with ResNet50.</p>
          <p> <b>1.  Convolutional Neural Network (CNN)  </b>: In this approach, we design a custom CNN architecture tailored to our specific problem. We create convolutional and pooling layers to extract features from the images, followed by fully connected layers to make predictions. Although this approach allows for more control over the architecture, it requires a significant amount of data and computational resources to achieve satisfactory results, as the model needs to learn everything . </p>

          <p> <b>2. Transfer Learning with VGG16</b>:  Instead of building a CNN , we can leverage pre-trained models like VGG16 that have already learned general features from a large dataset (e.g., ImageNet). We replace the original fully connected layers with new ones, specifically designed for our dog breed classification task. By freezing the weights of the convolutional layers, we can fine-tune the model using less computational resources and time compared to training the whole network. The VGG16 model is known for its simplicity and strong performance on image classification tasks.</p>

          <p> <b>3. Transfer Learning with ResNet50</b>: Similar to the VGG16 approach, we use another pre-trained model, ResNet50, for transfer learning. ResNet50 is a more complex and deeper architecture, which leverages residual connections to facilitate the training of deeper networks. It is known for its excellent performance on a wide range of image classification tasks. We follow the same process as with VGG16, replacing the original fully connected layers and training only the new layers for our dog breed classification problem.</p>
          <p> By comparing the performance, training time, and the number of parameters for each strategy, we can choose the most suitable approach for our problem. Transfer learning techniques, like VGG16 and ResNet50, often lead to better results and require less training time than building a CNN. However, it's essential to consider the trade-offs between computational resources, training time, and model complexity when selecting the best strategy for solving the problem.</p>

          <h1><b>Metrics With Justification</b>
          </h1>
          <p>In this project, we use accuracy as the primary metric to evaluate and compare the performance of our models. Accuracy is defined as the proportion of correctly classified images out of the total number of images in the dataset. It is a simple and intuitive metric that is widely used in classification problems. The formula for accuracy is:</p>
          <p> <b>Accuracy = (Number of correct predictions) / (Total number of predictions)</b></p>
          <p>Justification for using accuracy as the metric:</p>
          <p> <b>1. Balanced Dataset </b>: In our dataset, we have 133 different dog breeds, and the images are relatively evenly distributed among these breeds. This balance allows us to use accuracy as a reliable metric, as it is less likely to be biased towards a particular class.</p>

          <p> <b>2. Easy Interpretability</b>: Accuracy is a straightforward metric to understand and interpret, making it easy to communicate the performance of the model to non-technical stakeholders..</p>

          <p> <b>3. Comparability</b>: As accuracy is a commonly used metric in classification tasks, it allows us to compare the performance of our model with other models or benchmarks in the domain.</p>

          <p> <b>4. Suitable for Multiclass Problems</b>:  Accuracy is a suitable metric for multiclass classification problems like dog breed classification, as it provides a single value that summarizes the overall performance of the model across all classes.</p>
          <p> By comparing the performance, training time, and the number of parameters for each strategy, we can choose the most suitable approach for our problem. Transfer learning techniques, like VGG16 and ResNet50, often lead to better results and require less training time than building a CNN. However, it's essential to consider the trade-offs between computational resources, training time, and model complexity when selecting the best strategy for solving the problem.</p>
          <p>It is important to note that accuracy may not always be the best metric for every classification problem. For imbalanced datasets, other metrics like precision, recall, F1-score, or the area under the receiver operating characteristic (ROC) curve might be more appropriate. However, given the nature of our problem and the balanced dataset, accuracy serves as a suitable metric for evaluating the performance of our dog breed classification models.</p>
          <h1><b>Import Datasets</b>
          </h1>
          <p>We start by importing the necessary libraries and datasets. The algorithm uses two datasets: </p>
          <img src="import.png" id="image1" style="display:none;">
          <button onclick="toggleImage('image1')">Show/Hide Dog Data Set/Results</button>

          <img src="import2.png" id="image2" style="display:none;">
          <button onclick="toggleImage('image2')">Show/Hide Human Data Set/Results</button>

          <script>
            function toggleImage(imageId) {
              var image = document.getElementById(imageId);
              if (image.style.display === "none") {
                // Image is hidden, show it
                image.style.display = "block";
              } else {
                // Image is visible, hide it
                image.style.display = "none";
              }
            }
          </script>


          <p><b>Human face images</b>: This dataset contains 13,233 human face images and is used to detect human faces in the input images. The face detection is performed using OpenCV's cv2.CascadeClassifier class and the detectMultiScale method.</p>
          <div style="text-align: center;">
            <img src="humansamples.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;">Human Samples</p>
          </div>
          <img src="humanface.png" id="image3" style="display:none;">
          <button onclick="toggleImage('image3')">Show/Hide Human Face Images Code/Results</button>


          <p><b>Dog images</b>: This dataset comprises 8,351 dog images categorized into 133 dog breeds. The images are divided into training (6,680 images), validation (835 images), and test (836 images) sets. The dog detection is performed using a pre-trained ResNet-50 model from the torchvision library.</p>
          <div style="text-align: center;">
            <img src="dogsamples.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;">Dog Samples</p>
          </div>
          <img src="dogface.png" id="image4" style="display:none;">
          <button onclick="toggleImage('image4')">Show/Hide Dog Face Images Code/Results</button>


          <p>The input data is loaded and preprocessed using various Python libraries such as sklearn, Keras, NumPy, and OpenCV. The code snippets provided demonstrate the process of loading the datasets, shuffling the human face images, detecting faces in the images, and calculating the percentage of detected faces in both sets. For detailed explanation about Loading and preprocessing the data please check <a href="https://keras.io/api/preprocessing/image/">this</a>.</p>
          <h1><b>Detect Humans</b>
          </h1>
          <p>The first step in the algorithm is to check if the input image contains a human face. To do this, we use the cv2.CascadeClassifier class and the detectMultiScale method to detect human faces in the image. If a human face is detected, we continue to the next step. Otherwise, we return an error message.
          </p>
          <div style="text-align: center;">
            <img src="Haar.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;"> Cascade structure for Haar classifiers </p>
          </div>
          <h1><b>Detect Dogs</b>
          </h1>
          <p>The second step in the algorithm is to check if the input image contains a dog. To do this, we use a pre-trained <a href="https://keras.io/api/applications/resnet/#resnet50-function">ResNet-50</a> model from the torchvision library. The model is trained on the ImageNet dataset, which includes a large number of dog images. We use the pre-trained model to predict the most likely dog breed for the input image. If a dog is detected, we continue to the next step. Otherwise, we return an error message.</p>
          <div style="text-align: center;">
            <img src="Resnet.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;"> ResNet50 Model Architecture </p>
          </div>
          <h1><b>Create a Convolutional Neural Networks to Classify Dog Breeds</b>
          </h1>
          <p>The third step in the algorithm is to create a <a href="https://keras.io/guides/sequential_model/">Convolutional Neural Network (CNN)</a> to classify dog breeds. We use the Keras library in Python to create the model. The model consists of several convolutional layers followed by max pooling layers and fully connected layers. For display i used GitHub Gist and <a href=https://dgschwend.github.io/netscope/quickstart.html>David Gschwend Netscope CNN Analyzer</a>. Please check this link: <a href="https://dgschwend.github.io/netscope/#/gist/6f2aab72546a563893c187cfb37620e4">Detailed Convolutional Neural Networks Diagram (CNN)</a> and architecture is as follows:</p>
          <div style="text-align: center;">
            <img src="CNN.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;"> <a href="https://dgschwend.github.io/netscope/#/gist/6f2aab72546a563893c187cfb37620e4">Detailed Convolutional Neural Networks Diagram (CNN)</a></p>
          </div>
          <p>  1. Convolutional layer with 32 filters of size 3x3, using a stride of 1, same padding, and ReLU activation.</p>
          <p>  2. Max pooling layer with a 2x2 window and stride of 2.</p>
          <p>  3. Convolutional layer with 64 filters of size 3x3, using a stride of 1, same padding, and ReLU activation.</p>
          <p>  4. Max pooling layer with a 2x2 window and stride of 2.</p>
          <p>  5. Convolutional layer with 128 filters of size 3x3, using a stride of 1, same padding, and ReLU activation.</p>
          <p>  6. Max pooling layer with a 2x2 window and stride of 2.</p>
          <p>  7. Convolutional layer with 256 filters of size 3x3, using a stride of 1, same padding, and ReLU activation.</p>
          <p>  8. Max pooling layer with a 2x2 window and stride of 2.</p>
          <p>  9. Convolutional layer with 256 filters of size 3x3, using a stride of 1, same padding, and ReLU activation.</p>
          <p>  10. Max pooling layer with a 2x2 window and stride of 2.</p>
          <p>  11. Global average pooling layer to reduce the spatial dimensions.</p>
          <p>  12. Batch normalization layer to normalize the features.</p>
          <p>  13. Fully connected layer with 133 units (number of dog breeds) and softmax activation.</p>
          <img src="strach.png" id="image5" style="display:none;">
          <button onclick="toggleImage('image5')">Show/Hide CNN Code</button>
          <img src="scratchresults.png" id="image8" style="display:none;">
          <button onclick="toggleImage('image8')">Show/Hide CNN Results</button>

          <p>After defining the model architecture, we train the model on the dog breed dataset. To evaluate the model, we calculate the test accuracy using the following code:</p>
          <p><b>First Test Results</b>: <img src="testresult.png"> </p>
          <p>In the subsequent sections of the article, we will delve into the improvements made to the model, providing a thorough explanation of the rationale behind each modification and discussing the resulting impact on the model's performance. Keep in mind that the initial test accuracy was 25.2392%. By implementing these enhancements, we aim to achieve a higher accuracy, thus making the model more effective at classifying dog breeds.</p>
          <h1><b>Use a Convolutional Neural Networks to Classify Dog Breeds (using Transfer Learning)</b>
          </h1>
          <p>The fourth step in the algorithm is to use <a href="https://cs231n.github.io/transfer-learning/">transfer learning</a> with a pre-trained CNN to classify dog breeds. We employ the <a href="https://neurohive.io/en/popular-networks/vgg16/">VGG-16 model</a>  from the torchvision library, which is pre-trained on the ImageNet dataset. We extract the bottleneck features from the VGG-16 model and replace the last fully connected layer with a new one that outputs 133 classes, one for each dog breed. By fine-tuning the model on the dog breed dataset, we aim to achieve better performance. The test accuracy obtained after implementing transfer learning with the VGG-16 model is 41.0278%. To further enhance the model, we will explore the use of other pre-trained models and their bottleneck features, as well as discuss the model architecture in more detail.</p>
          <div style="text-align: center;">
            <img src="vgg16.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;"> VGG16 </p>
          </div>
          <p><b>Second Test Results</b>: <img src="testresult2.png"> </p>
          <h1><b>Create a CNN to Classify Dog Breeds with Transfer Learning</b>
          </h1>
          <p>In the fifth step of the algorithm, we implement a CNN to classify dog breeds using transfer learning. We utilize the VGG-16 model, similar to what we did in step 4. However, this time we freeze all the convolutional layers and only train the last fully connected layer. By doing this, we can train the model more efficiently and with fewer computational resources.</p>
          <p>After training the model, we evaluate the test accuracy using the following code:</p>
          <p><b>Third Test Results</b>: <img src="testresult3.png"> </p>
          <p>The test accuracy achieved with the ResNet-50 model is 80.9809%.</p>
          <head>
          <style>
          table {
            width: 100%;
            border-collapse: collapse;
          }

          table, th, td {
            border: 1px solid black;
            padding: 8px;
            text-align: left;
          }

          th {
            background-color: #f2f2f2;
          }
          </style>
          </head>
          <body>

          <h2><b>Comparison Table</b></h2>
          <p>This comparison table presents the performance of three different models: a custom CNN built, and two transfer learning models using VGG16 and ResNet50. The table highlights the number of parameters, epoch count, training time, and accuracy for each model. It is evident that the transfer learning models, particularly ResNet50, achieve significantly higher accuracy compared to the custom CNN, while requiring fewer parameters and less training time. This demonstrates the effectiveness of transfer learning in achieving better results with a more efficient use of computational resources.</p>
          <table>
            <tr>
              <th>Model</th>
              <th>Number of Parameters</th>
              <th>Epoch Count</th>
              <th>Training Time(s)</th>
              <th>Accuracy</th>
            </tr>
            <tr>
              <th>Convolutional Neural Networks</th>
              <td>1013701</td>
              <td>15</td>
              <td>974.45</td>
              <td>25.2392%</td>
            </tr>
            <tr>
              <th>Transfer Learning (VGG16)</th>
              <td>68229</td>
              <td>20</td>
              <td>33.66</td>
              <td>41.0287%</td>
            </tr>
            <tr>
              <th>Transfer Learning (ResNet50)</th>
              <td>272517</td>
              <td>20</td>
              <td>30.46</td>
              <td>80.9809%</td>
            </tr>
          </table>

          </body>
          <p>    </p>
          <p>In the case of the custom CNN built from scratch at this project, increasing the number of epochs to 20 resulted in overfitting (Accuracy rate was around %14). Overfitting occurs when a model learns the training data too well, capturing noise and patterns that are not relevant to the problem at hand. This leads to poor generalization and lower accuracy on unseen data. On the other hand, underfitting happens when a model fails to capture the underlying patterns of the data, resulting in suboptimal performance on both the training and test datasets.
          <p>    </p>
          <div style="text-align: center;">
            <img src="overfitting.png">
            <p style="font-size: 18px; font-weight: bold; margin-top: 10px; color: blue;"> ML | Underfitting and Overfitting </p>
          </div>

          <p> Balancing the model's complexity and training process is crucial to avoid overfitting and underfitting. Techniques such as early stopping, regularization, and dropout can be employed to mitigate overfitting, while increasing model capacity and using more training data can help address underfitting. In our comparison, the transfer learning models, especially ResNet50, demonstrated a well-balanced performance, achieving high accuracy without overfitting, showcasing the benefits of leveraging pre-trained networks in improving generalization capabilities.</p>
          <p>    </p>
          <h1><b>Write your Algorithm</b></p>
          </h1>
          <p>The sixth step in the algorithm is to write the main algorithm that combines all the previous steps. The algorithm takes an input image, first checks if it contains a human face, then checks if it contains a dog, and finally classifies the dog breed using the best performing CNN model from steps 3 to 5.</p>
          <img src="final.png">
          <h1><b>Test Your Algorithm</b>
          </h1>
          <p>The last step in the algorithm is to test the accuracy of the classifier on a set of test images.</p>
          <img src="labrador.png">
          <img src="brittany.png">
          <h1><b>Improvements</b>
          </h1>
          <p>As for possible improvements, there are a few areas of the project that could be further developed. For instance, fine-tuning and data augmentation could be explored to potentially improve the accuracy of the model. Additionally, while the project is focused on predicting dog breeds, it could be beneficial to expand the scope to include mixed breed dogs as well. Mixed breed dogs can be more difficult to identify, but it could be helpful for owners and dogs to know their breed composition.</p>

          <p>Furthermore, the model's ability to identify humans that "look like dogs" could also be improved. There appears to be a problem with the Silky Terrier data, as this breed is often erroneously identified in human photos. Removing the Silky Terrier from the model's predictions seems to result in more accurate human identification. These are areas that could be explored in future iterations of the project.</p>
          <img src="terrier.png">
            </article>

        </div>
      </main>
      <footer class="site-footer">
        <div class="wrapper">
          <h2 class="footer-heading">Mehmet Emre Toktay</h2>
          <div class="footer-col-wrapper">
            <div class="footer-col footer-col-1">
              <ul class="contact-list">
                <li>
                  <a>
                    <span class="icon icon--github">
                      <svg viewBox="0 4.801209 28.3499966 18.7475815" enable-background="new 0 4.801209 28.3499966 18.7475815">
                        <path fill="#828282" d="M15.699194,17.7568531c-0.4572582,0.3048401-0.9145174,0.6096783-1.5241938,0.6096783
c-0.6096773,0-1.0669355-0.15242-1.5241938-0.6096783L0,6.7826605v16.1564522C0,23.2439518,0.3048387,23.54879,0.6096774,23.54879
h27.1306419c0.3048401,0,0.6096764-0.3048382,0.6096764-0.6096764V6.7826605L15.699194,17.7568531z" />
                        <path fill="#828282" d="M14.9370966,15.7754021L27.587904,4.801209H0.9145162l12.6508064,10.9741936
C13.870162,16.0802422,14.4798384,16.0802422,14.9370966,15.7754021z" />
                      </svg>
                    </span>
                    <span class="username">
                      <span class="__cf_email__" data-cfemail="e7848f8e97a7848b869e978893c9868e">emre.toktay@pardus.tech</span>
                    </span>
                  </a>
                </li>
                <li>
                  <a href="https://github.com/EmreToktay">
                    <span class="icon icon--github">
                      <svg viewBox="0 0 16 16" width="16px" height="16px">
                        <path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z" />
                      </svg>
                    </span>
                    <span class="username">EmreToktay</span>
                  </a>
                </li>
                <li>
                  <a href="https://instagram.com/tnazburka">
                    <span class="icon icon--instagram">
                      <?xml version="1.0" encoding="UTF-8" standalone="no"?>
                      <svg width="256px" height="256px" viewBox="0 0 256 256" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" preserveAspectRatio="xMidYMid">
                        <g>
                          <path d="M127.999746,23.06353 C162.177385,23.06353 166.225393,23.1936027 179.722476,23.8094161 C192.20235,24.3789926 198.979853,26.4642218 203.490736,28.2166477 C209.464938,30.5386501 213.729395,33.3128586 218.208268,37.7917319 C222.687141,42.2706052 225.46135,46.5350617 227.782844,52.5092638 C229.535778,57.0201472 231.621007,63.7976504 232.190584,76.277016 C232.806397,89.7746075 232.93647,93.8226147 232.93647,128.000254 C232.93647,162.177893 232.806397,166.225901 232.190584,179.722984 C231.621007,192.202858 229.535778,198.980361 227.782844,203.491244 C225.46135,209.465446 222.687141,213.729903 218.208268,218.208776 C213.729395,222.687649 209.464938,225.461858 203.490736,227.783352 C198.979853,229.536286 192.20235,231.621516 179.722476,232.191092 C166.227425,232.806905 162.179418,232.936978 127.999746,232.936978 C93.8200742,232.936978 89.772067,232.806905 76.277016,232.191092 C63.7971424,231.621516 57.0196391,229.536286 52.5092638,227.783352 C46.5345536,225.461858 42.2700971,222.687649 37.7912238,218.208776 C33.3123505,213.729903 30.538142,209.465446 28.2166477,203.491244 C26.4637138,198.980361 24.3784845,192.202858 23.808908,179.723492 C23.1930946,166.225901 23.0630219,162.177893 23.0630219,128.000254 C23.0630219,93.8226147 23.1930946,89.7746075 23.808908,76.2775241 C24.3784845,63.7976504 26.4637138,57.0201472 28.2166477,52.5092638 C30.538142,46.5350617 33.3123505,42.2706052 37.7912238,37.7917319 C42.2700971,33.3128586 46.5345536,30.5386501 52.5092638,28.2166477 C57.0196391,26.4642218 63.7971424,24.3789926 76.2765079,23.8094161 C89.7740994,23.1936027 93.8221066,23.06353 127.999746,23.06353 M127.999746,0 C93.2367791,0 88.8783247,0.147348072 75.2257637,0.770274749 C61.601148,1.39218523 52.2968794,3.55566141 44.1546281,6.72008828 C35.7374966,9.99121548 28.5992446,14.3679613 21.4833489,21.483857 C14.3674532,28.5997527 9.99070739,35.7380046 6.71958019,44.1551362 C3.55515331,52.2973875 1.39167714,61.6016561 0.769766653,75.2262718 C0.146839975,88.8783247 0,93.2372872 0,128.000254 C0,162.763221 0.146839975,167.122183 0.769766653,180.774236 C1.39167714,194.398852 3.55515331,203.703121 6.71958019,211.845372 C9.99070739,220.261995 14.3674532,227.400755 21.4833489,234.516651 C28.5992446,241.632547 35.7374966,246.009293 44.1546281,249.28042 C52.2968794,252.444847 61.601148,254.608323 75.2257637,255.230233 C88.8783247,255.85316 93.2367791,256 127.999746,256 C162.762713,256 167.121675,255.85316 180.773728,255.230233 C194.398344,254.608323 203.702613,252.444847 211.844864,249.28042 C220.261995,246.009293 227.400247,241.632547 234.516143,234.516651 C241.632039,227.400755 246.008785,220.262503 249.279912,211.845372 C252.444339,203.703121 254.607815,194.398852 255.229725,180.774236 C255.852652,167.122183 256,162.763221 256,128.000254 C256,93.2372872 255.852652,88.8783247 255.229725,75.2262718 C254.607815,61.6016561 252.444339,52.2973875 249.279912,44.1551362 C246.008785,35.7380046 241.632039,28.5997527 234.516143,21.483857 C227.400247,14.3679613 220.261995,9.99121548 211.844864,6.72008828 C203.702613,3.55566141 194.398344,1.39218523 180.773728,0.770274749 C167.121675,0.147348072 162.762713,0 127.999746,0 Z M127.999746,62.2703115 C91.698262,62.2703115 62.2698034,91.69877 62.2698034,128.000254 C62.2698034,164.301738 91.698262,193.730197 127.999746,193.730197 C164.30123,193.730197 193.729689,164.301738 193.729689,128.000254 C193.729689,91.69877 164.30123,62.2703115 127.999746,62.2703115 Z M127.999746,170.667175 C104.435741,170.667175 85.3328252,151.564259 85.3328252,128.000254 C85.3328252,104.436249 104.435741,85.3333333 127.999746,85.3333333 C151.563751,85.3333333 170.666667,104.436249 170.666667,128.000254 C170.666667,151.564259 151.563751,170.667175 127.999746,170.667175 Z M211.686338,59.6734287 C211.686338,68.1566129 204.809755,75.0337031 196.326571,75.0337031 C187.843387,75.0337031 180.966297,68.1566129 180.966297,59.6734287 C180.966297,51.1902445 187.843387,44.3136624 196.326571,44.3136624 C204.809755,44.3136624 211.686338,51.1902445 211.686338,59.6734287 Z" fill="#0A0A08"></path>
                        </g>
                      </svg>
                    </span>
                    <span class="username">tnazburka</span>
                  </a>
                </li>
                <li>
                  <a href="https://www.linkedin.com/in/memretoktay">
                    <span class="icon icon--linkedin">
                      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
                        <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z" />
                      </svg>
                    </span>
                    <span class="username"> memretoktay</span>
                  </a>
                </li>
              </ul>
            </div>
            <div class="footer-col footer-col-2">
              <p>Mehmet Emre Toktay is an analyst with deep knowledge in customer relations. He has worked as a customer experience and business intelligence specialist and is now eager to transition into a data scientist role. Enthusiastic about data, statistics, and continuous improvement. He has a passion for uncovering insights and solving complex problems. </p>
      </footer>
  </body>
</html>
